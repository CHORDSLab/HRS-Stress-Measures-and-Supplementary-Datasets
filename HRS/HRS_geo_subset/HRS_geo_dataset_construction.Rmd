---
title: "HRS Geographical Dataset Construction"
subtitle: "CHORDS Lab ‚Äì Washington State University"
author:
- "David Rice"
- "Jason Cross"
- "Shawna Beese"
date: "Last updated: 2025-08-24"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---

## Overview

This R Markdown script walks through the construction of a supplementary geographic dataset for allostatic (over)load research using data from the [Health and Retirement Study (HRS)](https://hrs.isr.umich.edu/).

‚ö†Ô∏è Before continuing, make sure you‚Äôve downloaded and the required raw data. See [`HRS_geo_access_guide.md`](https://insert_url_here) for instructions.

The [`HRS_geo_access_guide.md`](HRS_geo_access_guide.md) will walk you through downloading the data we will be pulling from in this script.
---

### What You‚Äôll Need to Run This Script

...

## Setup & Libraries

```{r install-packages, eval=FALSE}
install.packages(c("SAScii", "dplyr", "stringr"))
```

```{r libraries}
library(SAScii)
library(dplyr)
library(stringr)
```

---

## üìÅ Set File Path


```{r}

# Set to the location of your "HRS Data Products" folder
path <- "C:/Users/jason/OneDrive/Desktop/CHORDS Lab/HRS/HRS Data Products/" # Replace with the full path to your local "HRS Data Products" folder

#####################
# Append Regional Data
#####################

# Set path to 2022 HRSXRegion folder
setwd(file.path(path, "HRSXRegion2022v10Early"))

region = read.SAScii("HRSXREGION22.da", "HRSXREGION22.sas")

# Check number of columns in `region`
ncol(region)

```

```{r}
# Continue w/ David's code
full_data$HHID = unlist(lapply(full_data$unique_id,FUN = function(x){return(str_split_1(x[1],"_")[1])}))
region = region%>%mutate(unique_id = paste(HHID,PN,sep = "_"))

# Check if unique_id got added properly
names(region)[1:10] # peek at the beginning
tail(names(region)) # and the end
"unique_id" %in% names(region) # TRUE = success!

```
```{r}

# Select the required BEALE columns for 2003 and 2013 (from 2006-2022) -- include 2018, 2020 and 2022?
beale_columns <- c("BEALE2003_06", "BEALE2003_08", "BEALE2003_10", "BEALE2003_12", "BEALE2003_14", "BEALE2003_16", "BEALE2003_18", "BEALE2003_20", "BEALE2003_22",
                   "BEALE2013_06", "BEALE2013_08", "BEALE2013_10", "BEALE2013_12", "BEALE2013_14", "BEALE2013_16", "BEALE2013_18", "BEALE2013_20", "BEALE2013_22")

region_trim <- region %>%
  select(unique_id, all_of(beale_columns))  # Ensure `unique_id` is included with the BEALE columns

glimpse(region_trim)

```




```{r}

geo_subset <- region_trim %>%
  # 1) Long-ify both Beale schemes across years
  pivot_longer(
    cols = matches("^BEALE(2003|2013)_(06|08|10|12|14|16|18|20|22)$"),
    names_to = c("scheme", "yr2"),
    names_pattern = "BEALE(2003|2013)_(\\d{2})",
    values_to = "value"
  ) %>%
  # 2) Make a proper year and tidy scheme names
  mutate(
    survey_year = 2000 + as.integer(yr2),         # 06 -> 2006, 22 -> 2022
    scheme = paste0("Beale_", scheme)
  ) %>%
  select(unique_id, survey_year, scheme, value) %>%
  # 3) Wide-ify to get Beale_2003 and Beale_2013 columns side by side
  pivot_wider(
    names_from = scheme,
    values_from = value
  ) %>%
  # 4) Build the join key and keep only the desired columns
  mutate(id_year = paste(unique_id, survey_year, sep = "_")) %>%
  select(id_year, unique_id, survey_year, Beale_2003, Beale_2013) %>%
  arrange(unique_id, survey_year) %>%
  # (Optional) Drop rows where both are NA
  filter(!(is.na(Beale_2003) & is.na(Beale_2013)))

# Preview
glimpse(geo_subset)

# Save if you want a standalone file
# write_csv(geo_subset, "geo_subset.csv")


```

---

### Save and Export Prepared HRS Data (w/ geo data added)

Export the cleaned dataset for future use in your preferred format. Below are examples using both `write.csv()` and `saveRDS()`: 

```{r}

# Export as .csv
write.csv(hrs_data, "hrs_geo_dataset.csv")

```


### Optional -- Load your main HRS Allostatic (over)Load dataset and join with this Geographic dataset

If you've already compiled an HRS Allostatic (over)Load dataset and want to join it with the Geographic subset you just created, you can use the example code below: 

```{r}

# Load your exported HRS Allostatic (over)Load dataset

# preview your dataset to ensure it loaded properly

# join/bind on id_year

```

